{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EasyPointNet_PointSelection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhlu97/pn_pc_cls/blob/master/EasyPointNet_PointSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SGGRqEsBTX_",
        "colab_type": "text"
      },
      "source": [
        "# Easiest PointNet Possible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIItjvl-0v6X",
        "colab_type": "text"
      },
      "source": [
        "## Fetch ModelNet40 and Decompress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeMr-nS001Ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2bc344e8-30dc-4557-a152-9851f2676167"
      },
      "source": [
        "!wget https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 20:19:23--  https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1705117335 (1.6G) [application/zip]\n",
            "Saving to: ‘modelnet40_normal_resampled.zip’\n",
            "\n",
            "modelnet40_normal_r 100%[===================>]   1.59G  5.66MB/s    in 2m 29s  \n",
            "\n",
            "2020-04-28 20:21:53 (10.9 MB/s) - ‘modelnet40_normal_resampled.zip’ saved [1705117335/1705117335]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrCTYNuq02px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip modelnet40_normal_resampled.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrQmdNrxBdd3",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MsGEo9sBlkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import logging\n",
        "# from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_9u9KBWEldg",
        "colab_type": "text"
      },
      "source": [
        "## Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcAA2WSZEkzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 60\n",
        "sample_point_count = 1024\n",
        "num_classes = 40\n",
        "num_epoch = 200\n",
        "learning_rate = 0.001\n",
        "# rootPath = '/content/modelnet40_normal_resampled/'\n",
        "rootPath = '/home/haokun/Downloads/modelnet40_normal_resampled'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuf7qUU_CSL3",
        "colab_type": "text"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO74ZvoEM_Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def farthest_point_sample(points, M):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        points: point cloud data matrix, [N, 3]\n",
        "        M: number of samples required\n",
        "    Return:\n",
        "        sample: resampled point cloud with farthest point sample approach, [M, 3]\n",
        "    \"\"\"\n",
        "    N, _ = points.shape\n",
        "\n",
        "    # results set\n",
        "    idx = np.zeros((M,))\n",
        "    # distance history\n",
        "    distance = np.ones((N,)) * 100\n",
        "\n",
        "    # initialize with a random point\n",
        "    far_idx = np.random.randint(0, N)\n",
        "    idx[0] = far_idx\n",
        "    centroid = points[far_idx]\n",
        "\n",
        "    for i in range(1,M):\n",
        "        cur_dist = np.sum((points - centroid) ** 2, 1)\n",
        "        distance[cur_dist < distance] = cur_dist[cur_dist < distance]\n",
        "        far_idx = np.argmax(distance, 0)\n",
        "        # input the this point into the final result set\n",
        "        centroid = points[far_idx]\n",
        "        idx[i] = far_idx\n",
        "\n",
        "    sample = points[idx.astype(np.int32)]\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaawGnGFnpXD",
        "colab_type": "text"
      },
      "source": [
        "### To use Pytorch's built-in dataloader, must implement subclass and override all three functions below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdHrasQRCvFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelNetResampledLoader(Dataset):\n",
        "  def __init__(self, rootPath, mode):\n",
        "        self.categoryNames = [line.rstrip() for line in open(os.path.join(rootPath, 'modelnet40_shape_names.txt'))]\n",
        "        self.classes = dict(zip(self.categoryNames, range(len(self.categoryNames))))\n",
        "\n",
        "        self.all_IDs = {}\n",
        "        self.all_IDs['train'] = [line.rstrip() for line in open(os.path.join(rootPath, 'modelnet40_train.txt'))]\n",
        "        self.all_IDs['test']  = [line.rstrip() for line in open(os.path.join(rootPath, 'modelnet40_test.txt'))]   \n",
        "\n",
        "        shape_names = ['_'.join(x.split('_')[0:-1]) for x in self.all_IDs[mode]]\n",
        "        self.datapath = [(shape_names[i], os.path.join(rootPath, shape_names[i], self.all_IDs[mode][i]) + '.txt') for i\n",
        "                         in range(len(self.all_IDs[mode]))]        \n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.datapath)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        selectedDatapaths = self.datapath[index]\n",
        "        selectedClasses   = self.classes[selectedDatapaths[0]]\n",
        "        selectedClasses   = np.array([selectedClasses]).astype(np.int32)\n",
        "\n",
        "        pointSet = np.loadtxt(selectedDatapaths[1], delimiter=',').astype(np.float32)\n",
        "        # pointSet = pointSet[0:sample_point_count,:] #Only choosing first 1024? -- Points have no ordering. We can already see shape with first 1024 pts\n",
        "        pointSet = farthest_point_sample(pointSet, sample_point_count)\n",
        "        pointSet = pointSet[:, 0:3]\n",
        "\n",
        "        return pointSet, selectedClasses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC-BxaFgotWJ",
        "colab_type": "text"
      },
      "source": [
        "## Simpliest PointNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wh7MyRwoycu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class STNkd(torch.nn.Module):\n",
        "    def __init__(self, k=64):\n",
        "        super(STNkd, self).__init__()\n",
        "\n",
        "        self.expand = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(k, 64, 1),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv1d(64, 128, 1),\n",
        "            torch.nn.BatchNorm1d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv1d(128, 1024, 1),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.shrink = torch.nn.Sequential(\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.BatchNorm1d(512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256),\n",
        "            torch.nn.BatchNorm1d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, k * k),\n",
        "        )\n",
        "\n",
        "        self.k = k     \n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = self.expand(x)\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.shrink(x)\n",
        "\n",
        "        init_id = Variable(torch.eye(self.k)).view(1, self.k * self.k).repeat(batchsize, 1).cuda()\n",
        "        x += init_id\n",
        "        x = x.view(-1, self.k, self.k)\n",
        "\n",
        "        return x\n",
        "\n",
        "class PointNetEncoder(torch.nn.Module):\n",
        "    def __init__(self, channel=3):\n",
        "        super(PointNetEncoder, self).__init__()\n",
        "\n",
        "        self.tNet3 = STNkd(channel)\n",
        "        self.featureExpansion_3_64 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(channel, 64, 1),\n",
        "            torch.nn.BatchNorm1d(64)\n",
        "        )\n",
        "        self.tNet64 = STNkd(64)\n",
        "        self.featureExpansion_64_128_1024 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(64, 64, 1),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.Conv1d(64, 128, 1),\n",
        "            torch.nn.BatchNorm1d(128),\n",
        "            torch.nn.Conv1d(128, 1024, 1),\n",
        "            torch.nn.BatchNorm1d(1024)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, D, N = x.size()\n",
        "\n",
        "        inputTransform = self.tNet3(x)\n",
        "        \n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, inputTransform)\n",
        "        x = x.transpose(2, 1)\n",
        "\n",
        "        x = self.featureExpansion_3_64(x)\n",
        "        featTranform = self.tNet64(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, featTranform)\n",
        "        x = x.transpose(2, 1)\n",
        "\n",
        "        pointfeat = x\n",
        "        x = self.featureExpansion_64_128_1024(x)\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        return x, inputTransform, featTranform\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, channel = 3):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.pointNetEncoder = PointNetEncoder(channel=channel)\n",
        "\n",
        "        self.pointNetDecoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.BatchNorm1d(512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256),\n",
        "            torch.nn.Dropout(p=0.4),\n",
        "            torch.nn.BatchNorm1d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, num_classes),\n",
        "            torch.nn.Softmax(dim = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, inputTransform, featTranform = self.pointNetEncoder(x)\n",
        "        x = self.pointNetDecoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Loss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Loss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        loss = torch.nn.functional.nll_loss(pred, target)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRKCWcgpzQGO",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_JSDlG2zl-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "825a0f93-f56a-4355-a1e5-0f6084c71caf"
      },
      "source": [
        "# Get data loader\n",
        "trainData = ModelNetResampledLoader(rootPath=rootPath, mode='train')\n",
        "testData  = ModelNetResampledLoader(rootPath=rootPath, mode='test')\n",
        "trainDataLoader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testDataLoader  = torch.utils.data.DataLoader(testData, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Get model\n",
        "model = Model().cuda()\n",
        "criterion = Loss().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # Print model's state_dict\n",
        "# print(\"Model's state_dict:\")\n",
        "# for param_tensor in model.state_dict():\n",
        "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# # Print optimizer's state_dict\n",
        "# print(\"Optimizer's state_dict:\")\n",
        "# for var_name in optimizer.state_dict():\n",
        "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-43b5bc5470e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelNetResampledLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestData\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mModelNetResampledLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainDataLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestDataLoader\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-451fc46bbd49>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rootPath, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModelNetResampledLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategoryNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modelnet40_shape_names.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategoryNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategoryNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/haokun/Downloads/modelnet40_normal_resampled/modelnet40_shape_names.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPUdrz7nzSjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Start training... Batch size： %d' % batch_size)\n",
        "epoch_accuracy = []\n",
        "epoch_loss = []\n",
        "for epoch in range(0,num_epoch):\n",
        "    correctRates = []\n",
        "    lossCur = []\n",
        "    for batch_id, data in tqdm(enumerate(trainDataLoader, 0), total=len(trainDataLoader)):\n",
        "        points, target = data\n",
        "        points = points.data.numpy()\n",
        "        points = torch.Tensor(points)\n",
        "        target = target[:, 0]\n",
        "\n",
        "        points = points.transpose(2, 1)\n",
        "        points, target = points.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        model = model.train()\n",
        "        pred = model(points)\n",
        "        loss = criterion(pred, target.long())\n",
        "        lossCur.append(loss.data.cpu().numpy())\n",
        "        pred_choice = pred.data.max(1)[1]\n",
        "        correct = pred_choice.eq(target.long().data).cpu().sum()\n",
        "        correctRates.append(correct.item() / float(points.size()[0]))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    trainEpochAccuracy = np.mean(correctRates)\n",
        "    print('Train Epoch %d Accuracy: %f' %(epoch, trainEpochAccuracy))\n",
        "    epoch_accuracy.append(trainEpochAccuracy)\n",
        "    epoch_loss.append(np.exp(np.mean(lossCur))) # what we are using is negative log likelihood loss\n",
        "\n",
        "torch.save(model, 'model.pytorch')\n",
        "\n",
        "# np.save(\"epoch_accuracy.npy\", epoch_accuracy)\n",
        "# np.save(\"epoch_loss.npy\", epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksusptd5ph4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, 'model.pytorch')\n",
        "np.save(\"epoch_accuracy.npy\", epoch_accuracy)\n",
        "np.save(\"epoch_loss.npy\", epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhmEJv9yHU_4",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96xu7MDSIupR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "model = torch.load('model.pytorch')\n",
        "model.eval()\n",
        "\n",
        "mean_correct = []\n",
        "class_acc = np.zeros((num_classes,3))\n",
        "for batch_id, data in tqdm(enumerate(testDataLoader), total=len(testDataLoader)):\n",
        "    points, target = data\n",
        "    target = target[:, 0]\n",
        "    points = points.transpose(2, 1)\n",
        "    points, target = points.cuda(), target.cuda()\n",
        "    classifier = model.eval()\n",
        "    pred = classifier(points)\n",
        "    pred_choice = pred.data.max(1)[1].type(torch.cuda.IntTensor)\n",
        "    equalCount = (pred_choice == target).cpu().sum()\n",
        "    mean_correct.append(equalCount.item() / float(points.size()[0]))\n",
        "instance_acc = np.mean(mean_correct)\n",
        "print('Test Instance Accuracy: %f' % instance_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCnEttsXKGsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}